# Automated Perspective Correction for Scanned Documents and Cards

Status: Done

### **Overview**

Modern scanning applications, such asÂ **CamScanner**Â or built-in iPad scanning tools, employÂ **perspective correction**Â to automatically detect and straighten skewed documents. This process ensures that scanned images appearÂ **parallel to the camera viewpoint**Â and aligned properly, eliminating distortions caused by camera angles.

Many existing solutions requireÂ **manual input**â€”users must provide four corner points of the document to perform perspective transformation. However, a robustÂ **automated pipeline**Â can detect these corners and apply corrections without user intervention.

This project implementsÂ **fully automated perspective correction**Â usingÂ **computer vision techniques**. Given an image of a tilted card or document, the system:

- [ ]  **Identifies edges and contours**
- [ ]  **Extracts the quadrilateral shape**
- [ ]  **Applies perspective transformation**Â to rectify the angle
- [ ]  **Enhances the image via sharpening**

---

## **Pipeline Overview**

The high-level workflow consists of the following steps:

1. **Read Image**Â â€“ Load the image and preprocess it.
2. **Edge Detection**Â â€“ UseÂ **Canny edge detection**Â to extract edges.
3. **Find Contours & Convex Hull**Â â€“ Identify closed shapes.
4. **Detect Intersections**Â â€“ Compute the intersection points forming the quadrilateral.
5. **Validate Quadrilateral Shape**Â â€“ Ensure detected points form a valid four-cornered structure.
6. **Compute Centroid & Sort Corners**Â â€“ Order the corners correctly for transformation.
7. **Apply Perspective Transformation**Â â€“ UseÂ **homography**Â to correct the skew.
8. **Warp Image**Â â€“ Perform the transformation to align the document.
9. **Sharpen & Enhance**Â â€“ Post-process the output for improved clarity.

---

## **Implementation Details**

### **1. Edge and Contour Detection**

The input image, typically aÂ **RGB image (Red-Green-Blue)**, is firstÂ **converted to grayscale (0-255 intensity range)**. This simplifies further processing by allowing edge detection algorithms to operate efficiently.

We employÂ **Canny Edge Detection**, a widely used algorithm that appliesÂ **Gaussian filtering, gradient computation, non-maximum suppression, and hysteresis thresholding**Â to extract prominent edges in the image.

```jsx
edges = cv2.Canny(image, threshold1=100, threshold2=150)
```

Once edges are detected, we extractÂ **contours and the convex hull**Â to identify shapes within the image.

---

### **2. Quadrilateral Detection**

The system analyzes the detected contours to determine if they form aÂ **quadrilateral**. This is achieved through:

- **Finding intersection points**Â of contour edges
- **Filtering valid four-cornered shapes**
- **Sorting the corners (Top-Left, Top-Right, Bottom-Left, Bottom-Right)**

If a quadrilateral is successfully detected, its centroid is computed to help distinguishÂ **top and bottom edges**.

```python
centroid_x = sum_x / len(points)
centroid_y = sum_y / len(points
```

Using centroid-based sorting, the corners are arranged in the correct order for transformation.

---

### **3. Perspective Transformation & Homography Correction**

Once theÂ **four corner points**Â are identified, we apply aÂ **homography transformation**Â to warp the image into a corrected perspective.

A homography is aÂ **3Ã—3 transformation matrixÂ HH**Â that maps points from the distorted plane to the corrected plane. It is computed usingÂ **OpenCVâ€™sÂ `cv2.getPerspectiveTransform()`Â function**:

```python
H = cv2.getPerspectiveTransform(source_corners, destination_corners)
warped_image = cv2.warpPerspective(image, H, (width, height)
```

Here:

- **`source_corners`**Â = Detected quadrilateral corners
- **`destination_corners`**Â = Mapped rectangle (aligned to the image frame)
- **`H`**Â = Homography matrix used for transformation

This step ensures that the output image is properly aligned, eliminating skewed perspectives.

---

### **4. Image Enhancement & Sharpening**

After the perspective correction, the transformed image may lose sharpness due toÂ **resampling artifacts**. To enhance clarity, we applyÂ **Gaussian blur and contrast adjustment**.

```python
blurred = cv2.GaussianBlur(warped_image, (5, 5), sigmaX=2)
sharpened = cv2.addWeighted(warped_image, 1.5, blurred, -0.5, 0)
```

ThisÂ **sharpens edges**Â while maintaining smoothness, making the final outputÂ **clearer and more readable**.

---

## **Technical Architecture**

### **1.Â `Coordinates`Â Class (Manages Intersection Points & Centroid)**

Handles:

- **Storage of detected intersections**
- **Centroid computation**Â for sorting corner points
- **Quadrilateral validation**

### **2.Â `Perspective`Â Class (Handles Perspective Transformation & Warping)**

Handles:

- **Edge detection**Â (`handle()`)
- **Contour & convex hull analysis**Â (`contourmethod()`)
- **Perspective transformation & warping**Â (`transform()`)
- **Sharpening & enhancement**Â (`showsharpen()`)

---

## **Code Repository & Resources**

Input:

![Screenshot 2025-01-30 at 5.05.05â€¯PM.png](Images/Screenshot_2025-01-30_at_5.05.05_PM.png)

Output:

![Screenshot 2025-01-30 at 5.09.57â€¯PM.png](Images/Screenshot_2025-01-30_at_5.09.57_PM.png)

ðŸ”—Â **GitHub**:Â [PerspectiveÂ CorrectionÂ Project](https://github.com/sraddhanjali/Perspective-Correction/blob/master/hough.py)

---

## **Conclusion**

This project provides aÂ **fully automated perspective correction pipeline**Â for scanned documents and cards. By leveragingÂ **edge detection, contour analysis, and homography transformation**, the system eliminates distortions and ensures aÂ **perfectly aligned scan without user input**.

This method can be extended to various applications, including:

- [ ]  **OCR (Optical Character Recognition)**
- [ ]  **Augmented Reality (AR) Registration**
- [ ]  **Robotic Vision & Object Alignment**

Future work includesÂ **deep learning-based quadrilateral detection**Â for enhanced accuracy and robustness.
